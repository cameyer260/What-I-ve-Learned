PDF Buffer to PNG Buffer in Node.js.
- After scanning the internet, I could not find any working NPM packages for converting pdfs to pngs in memory. The closest I found was a library that converts pdfs to pngs but requires that you save the png file somehwhere in the directory (pdf2pic). Other libraries were deprecated or did not work correctly. All of these packages usually rely on the ImageMagick OS binary, which you can use yourself in the code to convert pdfs to pngs in Node.js. You just need to open a child process using the Node.js spawn function. You can run the following code to take in a PDF buffer and return a png buffer of the first page of the PDF:

import { spawn } from "child_process";

/**
 * method for converting a pdf buffer to a png buffer.
 * uses the imagemagick binary.
 */
export async function getPdfPreview(pdfBuffer: Buffer): Promise<Buffer> {
  return new Promise((resolve, reject) => {
    const child = spawn('convert', [
      '-density', '150',
      'pdf:-[0]',           // Read PDF from stdin, first page only
      '-quality', '90',
      '-resize', '120x120',
      'png:-'               // Write PNG to stdout
    ]);

    const chunks: Buffer[] = [];
    const errors: Buffer[] = [];

    child.stdout.on('data', (chunk) => chunks.push(chunk));
    child.stderr.on('data', (chunk) => errors.push(chunk));

    child.on('close', (code) => {
      if (code === 0) {
        resolve(Buffer.concat(chunks));
      } else {
        reject(new Error(`ImageMagick failed: ${Buffer.concat(errors).toString()}`));
      }
    });

    child.on('error', (err) => {
      reject(new Error(`ImageMagick not found. Install with: brew install imagemagick`));
    });

    child.stdin.write(pdfBuffer);
    child.stdin.end();
  });
}

- This is the equivalent of spawning the ImageMagick CLI tool convert. You pass the array of arguments to it, 
density specifies the render resolution, pdf:- tells it to read a pdf from stdin, [0] tells it to only read the first page, 
png:- sends the png to stdout, -quality specifies the png quality, and resize specifies the scale image. You create buffer 
arrays after that, then on the child stdout (which will be the png buffer), you just take the chunk an dpush it to our chunks 
buffer, do the same with any error. Then on child close we check for an error and handle it if so, otherwise we return our png 
buffer. At the end of all that we send our pdf buffer in for the code we wrote and explained above to handle it.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

PDF Buffer to Text in Node.js
- After trying out several npm packages that just wrapped system binaries to convert pdf to text, I kept getting errors about
imports not being able to find the correct dependency, so I figured I'd just spawn a system binary itself to do it. I found 
poppler to be the best option for me, and found that you could pass - in the options to specify for stdin/stdout instead of
reading from and writing to a file in the path which worked in my use case much better. All I do in the following is spawn 
poppler's pdftotext cli command, pass - as the input and output options so it reads for a buffer and writes a buffer, and then
use the Node.js Buffer object's toString() method to convert to a string and return it from the function.


import { spawn } from "child_process";

/**
 * method for converting a pdf buffer to text.
 * uses the imagemagick binary.
 */
export async function getPdfText(pdfBuffer: Buffer): Promise<string> {
  return new Promise((resolve, reject) => {
    const child = spawn('pdftotext', [
      '-',
      '-',
    ]);

    const chunks: Buffer[] = [];
    const errors: Buffer[] = [];

    child.stdout.on('data', (chunk) => chunks.push(chunk));
    child.stderr.on('data', (chunk) => errors.push(chunk));

    child.on('close', (code) => {
      if (code === 0) {
        resolve(Buffer.concat(chunks).toString());
      } else {
        reject(new Error(`Poppler failed: ${Buffer.concat(errors).toString()}`));
      }
    });

    child.on('error', (err) => {
      reject(new Error(`Poppler not found. Install with: brew install poppler`));
    });

    child.stdin.write(pdfBuffer);
    child.stdin.end();
  });
}

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

Quick Git Notes

When you are making a new feature or bug fix or whatever, use the following to create a seperate branch to work on it on:

git checkout -b feature/name

or

git branch feature/name
git checkout feature/name

Then work on the feature, use git add. and git commit -m, push to github has well with git push origin feature/name.
Once it is completed and all working and ready for deployment, merge to main. To do this locally do:

git checkout main # switch to main
git pull origin main # make sure your main is up to date 
git merge feature/name 

# solve any merge conflicts in your editor, then git add . and git commit -m

# now you have merged the feature branch to main, you can now push to github 
git push origin main

# optionally cleanup branches as well
git branch -d feature/name # delete branch locally
git push origin --delete feature/name # delete branch from github as well

To do this on github (better for large features, staying organized, and working with others), you create a pull request on github after pushing
your feature branch to it. Then you can solve the merge conflicts if there are any and github will merge the branches to main and the tests and 
CI/CD will run. For simplicity and being a solo developer, doing it locally may be the better option for now.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

AWS S3 File/Image upload, and how to get a presigned url for them in Node.js.

First off make sure you have your bucket created, with an IAM user with at least get put and delete object commands, I just do admin priveledges to keep things simple.
Then only things you'll need to change from default config is adding the following CORS configuration in the permissions tab. Make sure you block public access and have
no conflicting ACLs or bucket policies as well. Here is the CORS config:

[
    {
        "AllowedHeaders": [
            "*"
        ],
        "AllowedMethods": [
            "GET",
            "PUT",
            "POST",
            "DELETE",
            "HEAD"
        ],
        "AllowedOrigins": [
            "*"
        ],
        "ExposeHeaders": [],
        "MaxAgeSeconds": 86400
    }
]

Then, after uploading the file to s3, you can get your presigned url. You'll first need to make sure you have downloaded @aws-sdk/s3-request-presigner via npm.
Then, you can import it like so: import { getSignedUrl } from "@aws-sdk/s3-request-presigner";
Then, you need to make a seperate s3 client to use your getPresignedUrl for because we'll need to disable a default that enforces the upload headers to be the 
exact same as the get headers, which they will not. Here is that client config:

export const presignedUrlClient = new S3Client({
  region: "us-east-2",
  credentials: {
    accessKeyId: process.env.S3_ACCESS_KEY as string,
    secretAccessKey: process.env.S3_SECRET_KEY as string,
  },
  // DISABLE all defaults that add upload-specific headers
  forcePathStyle: false,
});

Then you can get the presigned url. The entire upload/getPresignedUrl code will look like this. For deeper information, feel free to visit my project repo I am pulling
these examples from: https://github.com/cameyer260/docuquery 

const previewName = `user-${userId}/previews/${formData.get("name")}.png`;
const putPreviewCommand = new PutObjectCommand({
  Bucket: "docuquery-files",
  Key: previewName,
  Body: previewBuffer,
  ContentType: "image/png",
});
await s3client.send(putPreviewCommand);
awsPreview = previewName;

const getPreviewCommand = new GetObjectCommand({
  Bucket: "docuquery-files",
  Key: previewName,
});
const url = await getSignedUrl(presignedUrlClient, getPreviewCommand, { expiresIn: 3600 }); // 60 minutes
const expiry = new Date();
expiry.setMinutes(expiry.getMinutes() + 59); // take off a minute to be safe, it might take time for these lines of code to run


-----------------------------------------------------------------------------------------------------------------------------------------------------------------------

In C, all functions are pass by value, never pass by reference. Huge difference here when coming from higher level languages. This forces us to use double pointers often,
heres why:

int *pInt = (int*)malloc(sizeof(int));

// let's say we wanted to pass this pointer to a function and change what it actually points to (ignore the fact that this is specific example is bad practice because it
// will leave a memory leak)

void badFunction(int *p) {
    p = createPointer(); // set our pointer to a function that returns a pointer
}

// this is a bad function because the pointer being passed is just by value. the function receives the value of the pointer. when you go to set it to something else, it is 
// not the actual pointer passed from above being changed, but a copy of that being changed, badFunction's copy of it. so we are just setting the function's version 
// of the pointer, not the real pointer. using double pointers solves this, here is an example doing that:

int **pInt = (int*)malloc(sizeof(int));

void goodFunction(int **p) {
    *p = createPointer();
}

// this time, we pass a pointer to a pointer. so even though goodFunction is just receiving a copy of the value of the pointer, we can dereference it and change the pointer
// it points to in the memory, thus changing the actual pointer we have intended to change.

outerPointer -> innerPointer -> value

function(outerPointer) {
    dereference outPointer to get the location it points to, set that (which is innerPointer) to the new memory address for it to point to.
}

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------


